[
  {
    "objectID": "data_gathering/fdic_data_api_client.html",
    "href": "data_gathering/fdic_data_api_client.html",
    "title": "FDIC Data API Client",
    "section": "",
    "text": "By 503 Team 4\nSource: https://banks.data.fdic.gov/docs/#/"
  },
  {
    "objectID": "data_gathering/fdic_data_api_client.html#code",
    "href": "data_gathering/fdic_data_api_client.html#code",
    "title": "FDIC Data API Client",
    "section": "Code",
    "text": "Code\nImport libraries\n\nimport requests\nimport pandas as pd\nimport json\nimport urllib.parse\n\nDefine function\n\n# set endpoint\nendpoint = 'https://banks.data.fdic.gov/api/'\n\n# function\ndef get_all_financial_reporting_data(endpoint, reporting_period, fields, result_limit=5000):\n    \"\"\"\n    NC (Noninsured non-deposit commercial banks) are removed below to match the query of the FDIC site https://banks.data.fdic.gov/bankfind-suite/financialreporting\n    \"\"\"\n    \n    \n    # initialize data list\n    financials = []\n    \n    # query\n    fields_encoded = urllib.parse.quote(fields, safe='')\n    url = f'{endpoint}financials?filters=RISDATE:{reporting_period} AND !(BKCLASS:\"NC\")&fields={fields_encoded}&limit={result_limit}&sort_by=REPDTE&sort_order=ASC'\n    \n    # get response\n    response = requests.get(url)\n\n    if response.status_code == 200:\n        # response to json\n        data = response.json()\n\n        # store response data\n        financial_data = [item['data'] for item in data['data']]\n        financials.extend(financial_data)\n\n    else:\n        print(f'Request failed with status code {response.status_code}')\n        return None\n\n    return pd.DataFrame(financials)\n\nQuery the data\n\n# params\nreporting_period = '2022-12-31'\nfields = 'REPDTE,CERT,NAME,CITY,STNAME,ASSET,DEPDOM,BKCLASS,ADDRESS,ZIP,EQ,LIAB,ESTYMD,ENDEFYMD,' # no spaces between!\nresult_limit = 50\n\n# call\nall_financial_reporting_data = get_all_financial_reporting_data(endpoint, reporting_period, fields, result_limit)\n\n# display\nif all_financial_reporting_data is not None:\n    all_financial_reporting_data = all_financial_reporting_data.sort_values('CERT')\n    display(all_financial_reporting_data.head())\n    all_financial_reporting_data.to_csv(f'quarterly_financials/{reporting_period}_quarterly_financials.csv', index=False)\n\n\n\n\n\n\n\n\nZIP\nBKCLASS\nREPDTE\nDEPDOM\nASSET\nSTNAME\nEQ\nNAME\nCITY\nADDRESS\nENDEFYMD\nCERT\nESTYMD\nLIAB\nID\n\n\n\n\n7\n48858\nSM\n20221231\n1753341\n1981367\nMICHIGAN\n157576\nISABELLA BANK\nMOUNT PLEASANT\n200 E BROADWAY ST\n99991231\n1005\n19030701\n1823791\n1005_20221231\n\n\n12\n49230\nSM\n20221231\n101624\n113473\nMICHIGAN\n10543\nBANK MICHIGAN\nBROOKLYN\n417 S MAIN ST\n99991231\n1008\n19071001\n102930\n1008_20221231\n\n\n25\n49345\nSM\n20221231\n2126308\n2382585\nMICHIGAN\n192540\nCHOICEONE BANK\nSPARTA\n109 E DIVISION ST\n99991231\n1014\n18980101\n2190045\n1014_20221231\n\n\n49\n53818\nN\n20221231\n306266\n331939\nWISCONSIN\n16877\nCLARE BANK NATIONAL ASSN\nPLATTEVILLE\n345 W PINE ST\n99991231\n1022\n19051028\n315062\n1022_20221231\n\n\n0\n53946\nNM\n20221231\n123276\n148421\nWISCONSIN\n10659\nERGO BANK\nMARKESAN\n86 E WATER ST\n99991231\n10004\n19100120\n137762\n10004_20221231\n\n\n\n\n\n\n\nCheck data\n\ndisplay(all_financial_reporting_data.shape)\ncolumn_to_check = 'ACTIVE'\ndisplay(pd.DataFrame({'col1': all_financial_reporting_data[column_to_check].value_counts().index, 'count': all_financial_reporting_data[column_to_check].value_counts().values}))\n\n\n(4715, 15)\n\n\n\n\n\n\n\n\n\ncol1\ncount\n\n\n\n\n0\n1\n4715\n\n\n\n\n\n\n\nGet the last quarter for the past 30 years\n\ntoday = pd.Timestamp.now().date()\n\n\n# define the start and end dates of the range (inclusive)\nstart_date = '1992-03-31'\nend_date = '2012-03-31'\n\n# generate a list of dates within the range, with a frequency of 1 quarter\ndates = pd.date_range(start=start_date, end=end_date, freq='Q')\n\n# loop\nfor date in dates:\n\n    # get end of quarter\n    end_of_quarter = date.strftime('%Y-%m-%d') # format\n    \n    fields = 'REPDTE,CERT,NAME,CITY,STNAME,ASSET,DEPDOM,BKCLASS,ADDRESS,ZIP,EQ,LIAB,ESTYMD,ENDEFYMD,' # no spaces between!\n    result_limit = 10000\n\n    # call\n    all_financial_reporting_data = get_all_financial_reporting_data(endpoint, end_of_quarter, fields, result_limit)\n\n    # display\n    if all_financial_reporting_data is not None:\n        all_financial_reporting_data = all_financial_reporting_data.sort_values('CERT')\n        all_financial_reporting_data.to_csv(f'../../data/quarterly_financials/{end_of_quarter}_quarterly_financials.csv', index=False)\n        print(f'{end_of_quarter} done')\n\n1992-03-31 done"
  },
  {
    "objectID": "geospatial.html",
    "href": "geospatial.html",
    "title": "Geospatial",
    "section": "",
    "text": "Geospatial\n\nBanks have many offices. Locations mean the main office. As per the FDIC the main office is the headquarters listed in the charter. Which may not be the same as the corporate headquarter.\nAttempted to query all the addresses with geopy but estimated time would have been 16 hours of runtime.\nInstead we use the zip code coordiantes as proxy for the banks main offices.\n\nZip code data obtained from “ZIP Code Tabulation Areas” in https://www.census.gov/geographies/reference-files/time-series/geo/gazetteer-files.html\nWe use the Folium Python library - a leaflet.js wrapper - which will allow us to use OpenStreetMap.\nMany banks have moved to south dakota."
  },
  {
    "objectID": "plot-5.html",
    "href": "plot-5.html",
    "title": "Plot 5",
    "section": "",
    "text": "Plot 5\nLorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry’s standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.\nContrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old. Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur, from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of “de Finibus Bonorum et Malorum” (The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The first line of Lorem Ipsum, “Lorem ipsum dolor sit amet..”, comes from a line in section 1.10.32.\nThe standard chunk of Lorem Ipsum used since the 1500s is reproduced below for those interested. Sections 1.10.32 and 1.10.33 from “de Finibus Bonorum et Malorum” by Cicero are also reproduced in their exact original form, accompanied by English versions from the 1914 translation by H. Rackham."
  },
  {
    "objectID": "code.html",
    "href": "code.html",
    "title": "Code",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "plot-4.html",
    "href": "plot-4.html",
    "title": "Plot 4",
    "section": "",
    "text": "Plot 4\nLorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry’s standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.\nContrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old. Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur, from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of “de Finibus Bonorum et Malorum” (The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The first line of Lorem Ipsum, “Lorem ipsum dolor sit amet..”, comes from a line in section 1.10.32.\nThe standard chunk of Lorem Ipsum used since the 1500s is reproduced below for those interested. Sections 1.10.32 and 1.10.33 from “de Finibus Bonorum et Malorum” by Cicero are also reproduced in their exact original form, accompanied by English versions from the 1914 translation by H. Rackham."
  },
  {
    "objectID": "plot-3.html",
    "href": "plot-3.html",
    "title": "Plot 3",
    "section": "",
    "text": "Plot 3\nLorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry’s standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.\nContrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old. Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur, from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of “de Finibus Bonorum et Malorum” (The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The first line of Lorem Ipsum, “Lorem ipsum dolor sit amet..”, comes from a line in section 1.10.32.\nThe standard chunk of Lorem Ipsum used since the 1500s is reproduced below for those interested. Sections 1.10.32 and 1.10.33 from “de Finibus Bonorum et Malorum” by Cicero are also reproduced in their exact original form, accompanied by English versions from the 1914 translation by H. Rackham."
  },
  {
    "objectID": "plot-2.html",
    "href": "plot-2.html",
    "title": "Plot 2",
    "section": "",
    "text": "Plot 2\nLorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry’s standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.\nContrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old. Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur, from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of “de Finibus Bonorum et Malorum” (The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The first line of Lorem Ipsum, “Lorem ipsum dolor sit amet..”, comes from a line in section 1.10.32.\nThe standard chunk of Lorem Ipsum used since the 1500s is reproduced below for those interested. Sections 1.10.32 and 1.10.33 from “de Finibus Bonorum et Malorum” by Cicero are also reproduced in their exact original form, accompanied by English versions from the 1914 translation by H. Rackham."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "What is Lorem Ipsum?",
    "section": "",
    "text": "Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry’s standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.\n\n\nIt is a long established fact that a reader will be distracted by the readable content of a page when looking at its layout. The point of using Lorem Ipsum is that it has a more-or-less normal distribution of letters, as opposed to using ‘Content here, content here’, making it look like readable English. Many desktop publishing packages and web page editors now use Lorem Ipsum as their default model text, and a search for ‘lorem ipsum’ will uncover many web sites still in their infancy. Various versions have evolved over the years, sometimes by accident, sometimes on purpose (injected humour and the like).\n\nlibrary(gt)\ngt(mtcars)\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\n21.0\n6\n160.0\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160.0\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108.0\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258.0\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360.0\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225.0\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n14.3\n8\n360.0\n245\n3.21\n3.570\n15.84\n0\n0\n3\n4\n\n\n24.4\n4\n146.7\n62\n3.69\n3.190\n20.00\n1\n0\n4\n2\n\n\n22.8\n4\n140.8\n95\n3.92\n3.150\n22.90\n1\n0\n4\n2\n\n\n19.2\n6\n167.6\n123\n3.92\n3.440\n18.30\n1\n0\n4\n4\n\n\n17.8\n6\n167.6\n123\n3.92\n3.440\n18.90\n1\n0\n4\n4\n\n\n16.4\n8\n275.8\n180\n3.07\n4.070\n17.40\n0\n0\n3\n3\n\n\n17.3\n8\n275.8\n180\n3.07\n3.730\n17.60\n0\n0\n3\n3\n\n\n15.2\n8\n275.8\n180\n3.07\n3.780\n18.00\n0\n0\n3\n3\n\n\n10.4\n8\n472.0\n205\n2.93\n5.250\n17.98\n0\n0\n3\n4\n\n\n10.4\n8\n460.0\n215\n3.00\n5.424\n17.82\n0\n0\n3\n4\n\n\n14.7\n8\n440.0\n230\n3.23\n5.345\n17.42\n0\n0\n3\n4\n\n\n32.4\n4\n78.7\n66\n4.08\n2.200\n19.47\n1\n1\n4\n1\n\n\n30.4\n4\n75.7\n52\n4.93\n1.615\n18.52\n1\n1\n4\n2\n\n\n33.9\n4\n71.1\n65\n4.22\n1.835\n19.90\n1\n1\n4\n1\n\n\n21.5\n4\n120.1\n97\n3.70\n2.465\n20.01\n1\n0\n3\n1\n\n\n15.5\n8\n318.0\n150\n2.76\n3.520\n16.87\n0\n0\n3\n2\n\n\n15.2\n8\n304.0\n150\n3.15\n3.435\n17.30\n0\n0\n3\n2\n\n\n13.3\n8\n350.0\n245\n3.73\n3.840\n15.41\n0\n0\n3\n4\n\n\n19.2\n8\n400.0\n175\n3.08\n3.845\n17.05\n0\n0\n3\n2\n\n\n27.3\n4\n79.0\n66\n4.08\n1.935\n18.90\n1\n1\n4\n1\n\n\n26.0\n4\n120.3\n91\n4.43\n2.140\n16.70\n0\n1\n5\n2\n\n\n30.4\n4\n95.1\n113\n3.77\n1.513\n16.90\n1\n1\n5\n2\n\n\n15.8\n8\n351.0\n264\n4.22\n3.170\n14.50\n0\n1\n5\n4\n\n\n19.7\n6\n145.0\n175\n3.62\n2.770\n15.50\n0\n1\n5\n6\n\n\n15.0\n8\n301.0\n335\n3.54\n3.570\n14.60\n0\n1\n5\n8\n\n\n21.4\n4\n121.0\n109\n4.11\n2.780\n18.60\n1\n1\n4\n2"
  },
  {
    "objectID": "index.html#why-do-we-use-it",
    "href": "index.html#why-do-we-use-it",
    "title": "What is Lorem Ipsum?",
    "section": "",
    "text": "It is a long established fact that a reader will be distracted by the readable content of a page when looking at its layout. The point of using Lorem Ipsum is that it has a more-or-less normal distribution of letters, as opposed to using ‘Content here, content here’, making it look like readable English. Many desktop publishing packages and web page editors now use Lorem Ipsum as their default model text, and a search for ‘lorem ipsum’ will uncover many web sites still in their infancy. Various versions have evolved over the years, sometimes by accident, sometimes on purpose (injected humour and the like).\n\nlibrary(gt)\ngt(mtcars)\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\n21.0\n6\n160.0\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\n21.0\n6\n160.0\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\n22.8\n4\n108.0\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n21.4\n6\n258.0\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n18.7\n8\n360.0\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n18.1\n6\n225.0\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n14.3\n8\n360.0\n245\n3.21\n3.570\n15.84\n0\n0\n3\n4\n\n\n24.4\n4\n146.7\n62\n3.69\n3.190\n20.00\n1\n0\n4\n2\n\n\n22.8\n4\n140.8\n95\n3.92\n3.150\n22.90\n1\n0\n4\n2\n\n\n19.2\n6\n167.6\n123\n3.92\n3.440\n18.30\n1\n0\n4\n4\n\n\n17.8\n6\n167.6\n123\n3.92\n3.440\n18.90\n1\n0\n4\n4\n\n\n16.4\n8\n275.8\n180\n3.07\n4.070\n17.40\n0\n0\n3\n3\n\n\n17.3\n8\n275.8\n180\n3.07\n3.730\n17.60\n0\n0\n3\n3\n\n\n15.2\n8\n275.8\n180\n3.07\n3.780\n18.00\n0\n0\n3\n3\n\n\n10.4\n8\n472.0\n205\n2.93\n5.250\n17.98\n0\n0\n3\n4\n\n\n10.4\n8\n460.0\n215\n3.00\n5.424\n17.82\n0\n0\n3\n4\n\n\n14.7\n8\n440.0\n230\n3.23\n5.345\n17.42\n0\n0\n3\n4\n\n\n32.4\n4\n78.7\n66\n4.08\n2.200\n19.47\n1\n1\n4\n1\n\n\n30.4\n4\n75.7\n52\n4.93\n1.615\n18.52\n1\n1\n4\n2\n\n\n33.9\n4\n71.1\n65\n4.22\n1.835\n19.90\n1\n1\n4\n1\n\n\n21.5\n4\n120.1\n97\n3.70\n2.465\n20.01\n1\n0\n3\n1\n\n\n15.5\n8\n318.0\n150\n2.76\n3.520\n16.87\n0\n0\n3\n2\n\n\n15.2\n8\n304.0\n150\n3.15\n3.435\n17.30\n0\n0\n3\n2\n\n\n13.3\n8\n350.0\n245\n3.73\n3.840\n15.41\n0\n0\n3\n4\n\n\n19.2\n8\n400.0\n175\n3.08\n3.845\n17.05\n0\n0\n3\n2\n\n\n27.3\n4\n79.0\n66\n4.08\n1.935\n18.90\n1\n1\n4\n1\n\n\n26.0\n4\n120.3\n91\n4.43\n2.140\n16.70\n0\n1\n5\n2\n\n\n30.4\n4\n95.1\n113\n3.77\n1.513\n16.90\n1\n1\n5\n2\n\n\n15.8\n8\n351.0\n264\n4.22\n3.170\n14.50\n0\n1\n5\n4\n\n\n19.7\n6\n145.0\n175\n3.62\n2.770\n15.50\n0\n1\n5\n6\n\n\n15.0\n8\n301.0\n335\n3.54\n3.570\n14.60\n0\n1\n5\n8\n\n\n21.4\n4\n121.0\n109\n4.11\n2.780\n18.60\n1\n1\n4\n2"
  },
  {
    "objectID": "methods.html",
    "href": "methods.html",
    "title": "Methods",
    "section": "",
    "text": "Methods"
  },
  {
    "objectID": "authors.html",
    "href": "authors.html",
    "title": "Authors",
    "section": "",
    "text": "Authors\nAustin Barish abb110@georgetown.edu\nJordan Rinaldi jar388@georgetown.edu\nRaunak Advani ra1113@georgetown.edu\nVictor De Lima vad49@georgetown.edu"
  },
  {
    "objectID": "data_cleaning/geospatial_cleaning.html",
    "href": "data_cleaning/geospatial_cleaning.html",
    "title": "Data Cleaning - Geospatial Data",
    "section": "",
    "text": "import pandas as pd\nimport os\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nfrom geopy.geocoders import Nominatim\nimport folium\nimport ipywidgets as widgets\nfrom IPython.display import display\n# specify the directory containing the CSV files\ndirectory = '../../data/quarterly_financials'\n\n# create an empty list to store the dataframes\ndfs = []\n\n# loop over the CSV files in the directory\nfor filename in os.listdir(directory):\n    if filename.endswith('.csv'):\n        # read the CSV file into a dataframe and append it to the list\n        path = os.path.join(directory, filename)\n        df = pd.read_csv(path)\n        dfs.append(df)\n\n# concatenate the dataframes into a single dataframe\nquarterly_financials = pd.concat(dfs, ignore_index=True)\n# sort\nquarterly_financials = quarterly_financials.sort_values(by=['REPDTE', 'CERT'], ascending=[False, True])\nquarterly_financials = quarterly_financials.reset_index(drop=True)\n# print the combined dataframe\ndisplay(quarterly_financials.shape)\ndisplay(quarterly_financials.head())\n\n(971541, 15)\n\n\n\n\n\n\n\n\n\nZIP\nBKCLASS\nREPDTE\nDEPDOM\nASSET\nSTNAME\nEQ\nNAME\nCITY\nADDRESS\nENDEFYMD\nCERT\nESTYMD\nLIAB\nID\n\n\n\n\n0\n2111\nSM\n20221231\n163284000.0\n298020000\nMASSACHUSETTS\n26579000.0\nSTATE STREET BANK&TRUST CO\nBOSTON\n1 LINCOLN ST\n99991231.0\n14\n17920101\n271441000.0\n14_20221231\n\n\n1\n36830\nSM\n20221231\n952037.0\n1023366\nALABAMA\n65967.0\nAUBURNBANK\nAUBURN\n100 N GAY ST\n99991231.0\n35\n19070103\n957399.0\n35_20221231\n\n\n2\n36732\nNM\n20221231\n407949.0\n444822\nALABAMA\n32577.0\nROBERTSON BANKING CO\nDEMOPOLIS\n216 N WALNUT AVE\n99991231.0\n39\n18700101\n412245.0\n39_20221231\n\n\n3\n36867\nNM\n20221231\n266874.0\n265272\nALABAMA\n-8465.0\nPHENIX-GIRARD BANK\nPHENIX CITY\n801 13TH ST\n99991231.0\n41\n19040504\n273737.0\n41_20221231\n\n\n4\n36401\nNM\n20221231\n70649.0\n76239\nALABAMA\n5487.0\nBANK OF EVERGREEN\nEVERGREEN\n146 W FRONT ST\n99991231.0\n49\n19320901\n70752.0\n49_20221231\ndisplay(len(quarterly_financials['BKCLASS'].unique()))\ndisplay(quarterly_financials['BKCLASS'].unique())\n\n7\n\n\narray(['SM', 'NM', 'N', 'SI', 'SB', 'SL', 'OI'], dtype=object)\nZip coordinates\n# bring in\nzip_coordinates = pd.read_csv('../../data/coordinate_data/2022_Gaz_zcta_national.txt', sep='\\t')\n\n# remove whitespace in col names\nzip_coordinates.columns = [col.strip() for col in zip_coordinates.columns]\n\n# drop unnecesary columns\nzip_coordinates.drop(['ALAND', 'ALAND_SQMI', 'AWATER', 'AWATER_SQMI'], axis=1, inplace=True)\n\n# check\ndisplay(zip_coordinates.shape)\ndisplay(zip_coordinates.head())\n\n(33791, 3)\n\n\n\n\n\n\n\n\n\nGEOID\nINTPTLAT\nINTPTLONG\n\n\n\n\n0\n601\n18.180555\n-66.749961\n\n\n1\n602\n18.361945\n-67.175597\n\n\n2\n603\n18.457399\n-67.124867\n\n\n3\n606\n18.158327\n-66.932928\n\n\n4\n610\n18.293960\n-67.127182\ndisplay(len(quarterly_financials['ZIP'].unique()))\n\n10754\nCombine\n# Rename the 'GEOID' column in 'zip_coordinates' to match the 'ZIP' column in 'quarterly_financials'\nzip_coordinates = zip_coordinates.rename(columns={'GEOID': 'ZIP'})\n\n# Merge the two dataframes on the 'ZIP' column\nmerged_df = quarterly_financials.merge(zip_coordinates, on='ZIP', how='left')\n\n# Create a new column 'coordinates' with the combined 'INTPTLAT' and 'INTPTLONG' columns as a tuple\nmerged_df['zip_coordinates'] = list(zip(merged_df['INTPTLAT'], merged_df['INTPTLONG']))\n\n# Update the 'quarterly_financials' dataframe with the new 'coordinates' column\nquarterly_financials = merged_df\n\n# Print the updated 'quarterly_financials' dataframe\ndisplay(quarterly_financials.shape)\ndisplay(quarterly_financials.head())\n\n(971541, 18)\n\n\n\n\n\n\n\n\n\nZIP\nBKCLASS\nREPDTE\nDEPDOM\nASSET\nSTNAME\nEQ\nNAME\nCITY\nADDRESS\nENDEFYMD\nCERT\nESTYMD\nLIAB\nID\nINTPTLAT\nINTPTLONG\nzip_coordinates\n\n\n\n\n0\n2111\nSM\n20221231\n163284000.0\n298020000\nMASSACHUSETTS\n26579000.0\nSTATE STREET BANK&TRUST CO\nBOSTON\n1 LINCOLN ST\n99991231.0\n14\n17920101\n271441000.0\n14_20221231\n42.350680\n-71.060527\n(42.35068, -71.060527)\n\n\n1\n36830\nSM\n20221231\n952037.0\n1023366\nALABAMA\n65967.0\nAUBURNBANK\nAUBURN\n100 N GAY ST\n99991231.0\n35\n19070103\n957399.0\n35_20221231\n32.534872\n-85.493755\n(32.534872, -85.493755)\n\n\n2\n36732\nNM\n20221231\n407949.0\n444822\nALABAMA\n32577.0\nROBERTSON BANKING CO\nDEMOPOLIS\n216 N WALNUT AVE\n99991231.0\n39\n18700101\n412245.0\n39_20221231\n32.417456\n-87.892213\n(32.417456, -87.892213)\n\n\n3\n36867\nNM\n20221231\n266874.0\n265272\nALABAMA\n-8465.0\nPHENIX-GIRARD BANK\nPHENIX CITY\n801 13TH ST\n99991231.0\n41\n19040504\n273737.0\n41_20221231\n32.498054\n-85.023590\n(32.498054, -85.02359)\n\n\n4\n36401\nNM\n20221231\n70649.0\n76239\nALABAMA\n5487.0\nBANK OF EVERGREEN\nEVERGREEN\n146 W FRONT ST\n99991231.0\n49\n19320901\n70752.0\n49_20221231\n31.468970\n-86.950426\n(31.46897, -86.950426)\n# removed unmatched zips\nquarterly_financials.dropna(subset=['INTPTLAT'], inplace=True)\n\n# drop unnecesary columns\nquarterly_financials.drop(['INTPTLAT', 'INTPTLONG', 'ENDEFYMD', 'CERT', 'ESTYMD', 'LIAB', 'ID', 'ADDRESS', 'EQ', 'ZIP'], axis=1, inplace=True)\n\n# convert numerical values to millions (source is in thousands)\nquarterly_financials['DEPDOM'] = quarterly_financials['DEPDOM'].divide(1000)\nquarterly_financials['ASSET'] = quarterly_financials['ASSET'].divide(1000)\n\n# rename\nquarterly_financials.rename(columns={\n    'BKCLASS': 'bank_class', \n    'REPDTE': 'report_date', \n    'DEPDOM': 'deposits_mill', \n    'ASSET': 'assets_mill', \n    'STNAME': 'state', \n    'NAME': 'name',\n    'CITY': 'city'\n    }, inplace=True)\n\ndisplay(quarterly_financials.head())\n\n\n\n\n\n\n\n\nbank_class\nreport_date\ndeposits_mill\nassets_mill\nstate\nname\ncity\nzip_coordinates\n\n\n\n\n0\nSM\n20221231\n163284.000\n298020.000\nMASSACHUSETTS\nSTATE STREET BANK&TRUST CO\nBOSTON\n(42.35068, -71.060527)\n\n\n1\nSM\n20221231\n952.037\n1023.366\nALABAMA\nAUBURNBANK\nAUBURN\n(32.534872, -85.493755)\n\n\n2\nNM\n20221231\n407.949\n444.822\nALABAMA\nROBERTSON BANKING CO\nDEMOPOLIS\n(32.417456, -87.892213)\n\n\n3\nNM\n20221231\n266.874\n265.272\nALABAMA\nPHENIX-GIRARD BANK\nPHENIX CITY\n(32.498054, -85.02359)\n\n\n4\nNM\n20221231\n70.649\n76.239\nALABAMA\nBANK OF EVERGREEN\nEVERGREEN\n(31.46897, -86.950426)\n# change to title case\nquarterly_financials[['state', 'name', 'city']] = quarterly_financials[['state', 'name', 'city']].apply(lambda x: x.str.title())\n\n# format date\nquarterly_financials['report_date'] = pd.to_datetime(quarterly_financials['report_date'], format='%Y%m%d')\n\n# set to float\nquarterly_financials['deposits_mill'] = quarterly_financials['deposits_mill'].astype(float)\nquarterly_financials['assets_mill'] = quarterly_financials['assets_mill'].astype(float)\n\n\ndisplay(quarterly_financials.head())\n\n\n\n\n\n\n\n\nbank_class\nreport_date\ndeposits_mill\nassets_mill\nstate\nname\ncity\nzip_coordinates\n\n\n\n\n0\nSM\n2022-12-31\n163284.000\n298020.000\nMassachusetts\nState Street Bank&Trust Co\nBoston\n(42.35068, -71.060527)\n\n\n1\nSM\n2022-12-31\n952.037\n1023.366\nAlabama\nAuburnbank\nAuburn\n(32.534872, -85.493755)\n\n\n2\nNM\n2022-12-31\n407.949\n444.822\nAlabama\nRobertson Banking Co\nDemopolis\n(32.417456, -87.892213)\n\n\n3\nNM\n2022-12-31\n266.874\n265.272\nAlabama\nPhenix-Girard Bank\nPhenix City\n(32.498054, -85.02359)\n\n\n4\nNM\n2022-12-31\n70.649\n76.239\nAlabama\nBank Of Evergreen\nEvergreen\n(31.46897, -86.950426)\nquarterly_financials['bank_class'] = quarterly_financials['bank_class'].replace({\n    'N':  'Commercial bank, national charter, Fed member',\n    'NM': 'Commercial bank, state charter, Fed non-member',\n    'OI': 'Insured U.S. branch of a foreign chartered institution',\n    'SB': 'Federal savings banks',\n    'SI': 'State chartered stock savings banks',\n    'SL': 'State chartered stock savings and loan association',\n    'SM': 'Commercial bank, state charter, Fed member',\n    'NC': 'Noninsured non-deposit commercial bank',\n    'NS': 'Noninsured stock savings bank',\n    'CU': 'State or federally chartered credit union',\n    })\n\ndisplay(quarterly_financials.shape)\ndisplay(quarterly_financials.head())\n\n\n(937293, 8)\n\n\n\n\n\n\n\n\n\nbank_class\nreport_date\ndeposits_mill\nassets_mill\nstate\nname\ncity\nzip_coordinates\n\n\n\n\n0\nCommercial bank, state charter, Fed member\n2022-12-31\n163284.000\n298020.000\nMassachusetts\nState Street Bank&Trust Co\nBoston\n(42.35068, -71.060527)\n\n\n1\nCommercial bank, state charter, Fed member\n2022-12-31\n952.037\n1023.366\nAlabama\nAuburnbank\nAuburn\n(32.534872, -85.493755)\n\n\n2\nCommercial bank, state charter, Fed non-member\n2022-12-31\n407.949\n444.822\nAlabama\nRobertson Banking Co\nDemopolis\n(32.417456, -87.892213)\n\n\n3\nCommercial bank, state charter, Fed non-member\n2022-12-31\n266.874\n265.272\nAlabama\nPhenix-Girard Bank\nPhenix City\n(32.498054, -85.02359)\n\n\n4\nCommercial bank, state charter, Fed non-member\n2022-12-31\n70.649\n76.239\nAlabama\nBank Of Evergreen\nEvergreen\n(31.46897, -86.950426)\nquarterly_financials['zip_coordinates'].isna().sum()\n\n0"
  },
  {
    "objectID": "data_cleaning/geospatial_cleaning.html#growth-of-assets-with-slider",
    "href": "data_cleaning/geospatial_cleaning.html#growth-of-assets-with-slider",
    "title": "Data Cleaning - Geospatial Data",
    "section": "Growth of Assets with Slider",
    "text": "Growth of Assets with Slider\n\nfrom ipywidgets.embed import embed_minimal_html\nimport branca\nfrom IPython.display import HTML\n\n\ngdf = gpd.GeoDataFrame(quarterly_financials, geometry=gpd.points_from_xy(quarterly_financials.zip_coordinates.apply(lambda p: p[1]), quarterly_financials.zip_coordinates.apply(lambda p: p[0])))\n\n\ndef plot_bank_assets_by_date(date):\n    # Filter the GeoDataFrame by the selected date\n    filtered_gdf = gdf[gdf['report_date'] == date]\n\n    # Group the filtered GeoDataFrame by state and sum the assets\n    state_assets = filtered_gdf.groupby('state')['assets_mill'].sum().reset_index()\n\n    # Create the base folium map\n    m = folium.Map(location=[37.8, -96], zoom_start=4)\n\n    # Define a function to scale the assets to a suitable size for the map\n    def scale_bubble_size(assets):\n        return assets / 50000\n\n    # Plot bubbles for each state with a size proportional to the total assets\n    for index, row in state_assets.iterrows():\n        state_data = filtered_gdf[filtered_gdf['state'] == row['state']]\n        state_centroid = state_data.unary_union.centroid\n        folium.CircleMarker(\n            location=[state_centroid.y, state_centroid.x],\n            radius=scale_bubble_size(row['assets_mill']),\n            color='blue',\n            fill=True,\n            fill_color='blue',\n            fill_opacity=0.5,\n            popup=f\"State: {row['state']}&lt;br&gt;Total Assets: {row['assets_mill']:.0f}&lt;br&gt;Date: {date}\"\n        ).add_to(m)\n\n    # Display the map\n    return m\n\n\n\n# Get the unique report dates sorted\nunique_dates = sorted(quarterly_financials['report_date'].unique())\n\n# Create the index slider\nindex_slider = widgets.IntSlider(\n    min=0,\n    max=len(unique_dates) - 1,\n    description='Date Index:',\n    continuous_update=False,\n)\n\n# Create the play button\nplay_button = widgets.Play(\n    interval=100,  # Time in milliseconds between updates\n    value=0,  # Slider starting value\n    min=0,\n    max=len(unique_dates) - 1,\n    step=1,\n    description=\"Press play\",\n    disabled=False\n)\n\n# Link the play button to the index slider\nwidgets.jslink((play_button, 'value'), (index_slider, 'value'))\n\n# Create a horizontal box to display the slider and play button together\nslider_with_play = widgets.HBox([index_slider, play_button])\n\ndef display_map(index):\n    date = unique_dates[index]\n    m = plot_bank_assets_by_date(date)\n    display(m)\n\n# Use widgets.interactive() and assign the output to a variable\ninteractive_map = widgets.interactive(display_map, index=index_slider)\n\n# Clear the output of interactive_map (to prevent double display of the map)\ninteractive_map.update()\n\n\n# Display the slider with the play button and the interactive map\ndisplay(slider_with_play)\ndisplay(interactive_map.children[-1])\n\n\n\n\n\n\n\n\n\n\n\nfrom ipywidgets.embed import embed_minimal_html\nimport branca\nfrom IPython.display import HTML\n\n\ngdf = gpd.GeoDataFrame(quarterly_financials, geometry=gpd.points_from_xy(quarterly_financials.zip_coordinates.apply(lambda p: p[1]), quarterly_financials.zip_coordinates.apply(lambda p: p[0])))\n\n\ndef plot_bank_assets_by_date(date):\n    # Filter the GeoDataFrame by the selected date\n    filtered_gdf = gdf[gdf['report_date'] == date]\n\n    # Group the filtered GeoDataFrame by state and sum the assets\n    state_assets = filtered_gdf.groupby('state')['assets_mill'].sum().reset_index()\n\n    # Create the base folium map\n    m = folium.Map(location=[37.8, -96], zoom_start=4)\n\n    # Define a function to scale the assets to a suitable size for the map\n    def scale_bubble_size(assets):\n        return assets / 50000\n\n    # Plot bubbles for each state with a size proportional to the total assets\n    for index, row in state_assets.iterrows():\n        state_data = filtered_gdf[filtered_gdf['state'] == row['state']]\n        state_centroid = state_data.unary_union.centroid\n        folium.CircleMarker(\n            location=[state_centroid.y, state_centroid.x],\n            radius=scale_bubble_size(row['assets_mill']),\n            color='blue',\n            fill=True,\n            fill_color='blue',\n            fill_opacity=0.5,\n            popup=f\"State: {row['state']}&lt;br&gt;Total Assets: {row['assets_mill']:.0f}&lt;br&gt;Date: {date}\"\n        ).add_to(m)\n\n    # Display the map\n    return m\n\n\n# Get the unique report dates sorted\nunique_dates = sorted(quarterly_financials['report_date'].unique())\n\n# Create the index slider\nindex_slider = widgets.IntSlider(\n    min=0,\n    max=len(unique_dates) - 1,\n    description='Date Index:',\n    continuous_update=False,\n)\n\n# Create the play button\nplay_button = widgets.Play(\n    interval=100,  # Time in milliseconds between updates\n    value=0,  # Slider starting value\n    min=0,\n    max=len(unique_dates) - 1,\n    step=1,\n    description=\"Press play\",\n    disabled=False\n)\n\n# Link the play button to the index slider\nwidgets.jslink((play_button, 'value'), (index_slider, 'value'))\n\n# Create a horizontal box to display the slider and play button together\nslider_with_play = widgets.HBox([index_slider, play_button])\n\ndef display_map(index):\n    date = unique_dates[index]\n    m = plot_bank_assets_by_date(date)\n    display(m)\n\n# Use widgets.interactive() and assign the output to a variable\ninteractive_map = widgets.interactive(display_map, index=index_slider)\n\n# Clear the output of interactive_map (to prevent double display of the map)\ninteractive_map.update()\n\n# create a div to contain the widgets\nwidget_container = HTML('&lt;div id=\"widget-container\"&gt;&lt;/div&gt;')\n\n# add the slider and interactive map to the container\nwidget_container.children = [slider_with_play, interactive_map.children[-2]]\n\n\n# generate the HTML code for the widgets\nhtml_code = embed_minimal_html('bank_assets_map.html', views=[interactive_map], title='Bank Assets Map', )\n\n# display the HTML file in an IPython notebook\nHTML(filename='bank_assets_map.html')\n\n\n\n\n    \n    Bank Assets Map"
  },
  {
    "objectID": "data_cleaning/geospatial_cleaning.html#individual-points",
    "href": "data_cleaning/geospatial_cleaning.html#individual-points",
    "title": "Data Cleaning - Geospatial Data",
    "section": "Individual Points",
    "text": "Individual Points\nHeatmap all dates\nLatest date only\n\nimport folium\nfrom folium.plugins import HeatMap\nimport pandas as pd\nfrom IPython.display import IFrame\n\n# Find the latest date\nlatest_date = quarterly_financials['report_date'].max()\n\n# Filter the DataFrame by the latest date\nlatest_quarterly_financials = quarterly_financials[quarterly_financials['report_date'] == latest_date]\n\n# Create a base map\nmap = folium.Map(location=[37.8, -96], zoom_start=4)\n\n# Prepare the data for the HeatMap\nheatmap_data = []\nfor index, row in latest_quarterly_financials.iterrows():\n    coordinates = row['zip_coordinates']\n    assets_mill = row['assets_mill']\n    heatmap_data.append((*coordinates, assets_mill))\n\n# Add the HeatMap to the map\nheatmap = HeatMap(heatmap_data, radius=13, max_zoom=13, gradient={0.2: 'blue', 0.4: 'lime', 0.6: 'orange', 1: 'red'})\nmap.add_child(heatmap)\n\n# For rendering on Quarto\nmap.save('heatmap_latest_date.html')\nIFrame(src='heatmap_latest_date.html', width=700, height=600)\n\n# For rendering in Jupyter Notebook\ndisplay(map)\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\nimport folium\nfrom folium.plugins import HeatMap\nimport pandas as pd\nfrom IPython.display import IFrame\n\n# Find the latest date\nlatest_date = quarterly_financials['report_date'].max()\n\n# Filter the DataFrame by the latest date\nlatest_quarterly_financials = quarterly_financials[quarterly_financials['report_date'] == latest_date]\n\n# Create a base map\nmap = folium.Map(location=[37.8, -96], zoom_start=4)\n\n# Prepare the data for the HeatMap\nheatmap_data = []\nfor index, row in latest_quarterly_financials.iterrows():\n    coordinates = row['zip_coordinates']\n    assets_mill = row['assets_mill']\n    heatmap_data.append((*coordinates, assets_mill))\n\n# Add the HeatMap to the map\nheatmap = HeatMap(heatmap_data, radius=13, max_zoom=13, gradient={0.0: '#ffffb2', 0.25: '#fecc5c', 0.5: '#fd8d3c', 0.75: '#f03b20', 1.0: '#bd0026'}) # YlOrBr color scheme\nmap.add_child(heatmap)\n\n# Function to scale the assets to a suitable size for the map\ndef scale_bubble_size(assets):\n    return assets / 50000\n\n# Add CircleMarkers with tooltips to the map\nfor index, row in latest_quarterly_financials.iterrows():\n    coordinates = row['zip_coordinates']\n    assets_mill = row['assets_mill']\n    bank_name = row['name']\n    tooltip_text = f\"Bank: {bank_name}&lt;br&gt;Coordinates: {coordinates}&lt;br&gt;Assets (millions): {assets_mill}\"\n    folium.CircleMarker(\n        location=coordinates,\n        radius=scale_bubble_size(assets_mill),\n        color='blue',\n        fill=True,\n        fill_color='blue',\n        fill_opacity=0.5,\n        tooltip=tooltip_text,\n    ).add_to(map)\n\n# For rendering on Quarto\nmap.save('heatmap.html')\nIFrame(src='heatmap.html', width=700, height=600)\n\n# For rendering in Jupyter Notebook\ndisplay(map)\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "the_fdic.html",
    "href": "the_fdic.html",
    "title": "The FDIC",
    "section": "",
    "text": "The FDIC\n\n\nIntroduction\nOn Friday, March 10th, 2023, U.S. regulators seized Silicon Valley Bank (SVB) in the largest U.S. bank failure since the 2008 financial crisis. The 40-year-long bank operation suddenly stopped after depositors panicked when learning that the bank was short on capital. The bank found itself in this position due to several factors, including incorrect investment allocation and customers requiring to use more cash in the bank as Venture Capital firms cut back their funding (Vanian 2023). The public quickly turned its attention to the Federal Deposit Insurance Corporation (FDIC). The FDIC is an independent government agency tasked with insuring deposits, supervising financial institutions, and dealing with the orderly management of a bank failure. Most famously, the FDIC provides a standard insurance amount of $250,000 per depositor, per insured bank, which has accomplished for no depositor to lose a penny of insured funds due to a failure since 1934 (Federal Deposit Insurance Corporation 2020). It became apparent that the general public needed to be made aware of the FDIC system, its role in the financial system, and its importance in preserving the financial well-being of the U.S. population. In this report, we seek to provide a glimpse into the FDIC system and offer a rich visual representation of the system’s mechanics.\n\n\n\n\n\nReferences\n\nFederal Deposit Insurance Corporation. 2020. “What We Do.” Federal Deposit Insurance Corporation. https://www.fdic.gov/about/what-we-do/index.html.\n\n\nVanian, Jonathan, Rohan Goswami. 2023. “Here’s How the Second-Biggest Bank Collapse in U.S. History Happened in Just 48 Hours.” CNBC. https://www.cnbc.com/2023/03/10/silicon-valley-bank-collapse-how-it-happened.html."
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "Data"
  }
]